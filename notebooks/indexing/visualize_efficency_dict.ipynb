{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a8d003-e9af-45a7-bd29-0fe79bf1a621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aober\\AppData\\Local\\Temp\\ipykernel_20516\\1345563231.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  games.loc[:, 'moves'] = games['moves'].apply(lambda x: x.split() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 122>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m     games \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m    127\u001b[0m games \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(games)\n\u001b[1;32m--> 128\u001b[0m analyzed_games \u001b[38;5;241m=\u001b[39m \u001b[43mget_analyzed_games\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m plot_cached_positions_distribution(analyzed_games)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mget_analyzed_games\u001b[1;34m(games)\u001b[0m\n\u001b[0;32m     85\u001b[0m games \u001b[38;5;241m=\u001b[39m games[:n_games]\n\u001b[0;32m     86\u001b[0m games\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoves\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m games[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoves\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[1;32m---> 88\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_game_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstockfish_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskill_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mparallel_game_analysis\u001b[1;34m(games, stockfish_path, depth, skill_level, workers)\u001b[0m\n\u001b[0;32m     73\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(analyze_games, \u001b[38;5;241m*\u001b[39marg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m---> 75\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import chess\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from stockfish import Stockfish\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def load_evaluations_cache():\n",
    "    file_path = \"../../../data/indexed_positions/final_processed_index.json\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        cache = json.load(file)\n",
    "    return cache\n",
    "\n",
    "def initialize_stockfish(path, depth, skill_level):\n",
    "    stockfish = Stockfish(path)\n",
    "    stockfish.set_depth(depth)\n",
    "    stockfish.set_skill_level(skill_level)\n",
    "    return stockfish\n",
    "\n",
    "def build_stored_game_analysis(game, move_number, stockfish, evaluations_cache):\n",
    "    row = {}\n",
    "    row['move_number'] = move_number\n",
    "    board = chess.Board()\n",
    "\n",
    "    for san in game.moves[:move_number]:\n",
    "        move = board.parse_san(san)\n",
    "        board.push(move)\n",
    "\n",
    "    fen = board.fen()\n",
    "    row['fen'] = fen\n",
    "    row['cached'] = fen in evaluations_cache\n",
    "\n",
    "    if fen in evaluations_cache:\n",
    "        evaluation_value = evaluations_cache[fen]\n",
    "    else:\n",
    "        stockfish.set_fen_position(fen)\n",
    "        evaluation = stockfish.get_evaluation()\n",
    "        evaluation_value = evaluation['value']\n",
    "\n",
    "    row['evaluation'] = evaluation_value\n",
    "\n",
    "    return row\n",
    "\n",
    "def analyze_games(chunk, stockfish_path, depth, skill_level):\n",
    "    stockfish = initialize_stockfish(stockfish_path, depth, skill_level)\n",
    "    evaluations_cache = load_evaluations_cache()\n",
    "\n",
    "    all_game_analysis = []\n",
    "    for game in chunk.itertuples(index=False):\n",
    "        game_analysis = []\n",
    "        move_number = 1\n",
    "\n",
    "        while move_number <= len(game.moves):\n",
    "            analysis_result = build_stored_game_analysis(game, move_number, stockfish, evaluations_cache)\n",
    "            game_analysis.append(analysis_result)\n",
    "            move_number += 1\n",
    "\n",
    "        df = pd.DataFrame(game_analysis)\n",
    "        df.set_index('move_number', inplace=True)\n",
    "        all_game_analysis.append(df)\n",
    "\n",
    "    return all_game_analysis\n",
    "\n",
    "def parallel_game_analysis(games, stockfish_path, depth, skill_level, workers):\n",
    "    chunk_size = len(games) // workers\n",
    "    game_chunks = [games.iloc[i:i + chunk_size] for i in range(0, len(games), chunk_size)]\n",
    "    args = [(chunk, stockfish_path, depth, skill_level) for chunk in game_chunks]\n",
    "\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        futures = [executor.submit(analyze_games, *arg) for arg in args]\n",
    "        for future in as_completed(futures):\n",
    "            results.extend(future.result())\n",
    "    return results\n",
    "\n",
    "def get_analyzed_games(games):\n",
    "    n_games = 100 # len(games)\n",
    "    skill_level = 1\n",
    "    depth = 1\n",
    "    num_threads = 2  # Adjust the number of threads as necessary\n",
    "    stockfish_path = \"C:/Users/aober/Documents/Data_Science_Studium/4Semester/BigData/stockfish/stockfish-windows-x86-64-avx2.exe\"\n",
    "\n",
    "    games = games[:n_games]\n",
    "    games.loc[:, 'moves'] = games['moves'].apply(lambda x: x.split() if isinstance(x, str) else x)\n",
    "\n",
    "    results = parallel_game_analysis(games, stockfish_path, depth, skill_level, num_threads)\n",
    "    return results\n",
    "\n",
    "def plot_cached_positions_distribution(all_game_analysis):\n",
    "    move_numbers = []\n",
    "    cached_counts = []\n",
    "    not_cached_counts = []\n",
    "\n",
    "    for game_df in all_game_analysis:\n",
    "        cached_positions = game_df['cached'].value_counts().get(True, 0)\n",
    "        not_cached_positions = game_df['cached'].value_counts().get(False, 0)\n",
    "        move_numbers.extend(game_df.index)\n",
    "\n",
    "        cached_counts.extend([1 if cached else 0 for cached in game_df['cached']])\n",
    "        not_cached_counts.extend([0 if cached else 1 for cached in game_df['cached']])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'move_number': move_numbers,\n",
    "        'cached': cached_counts,\n",
    "        'not_cached': not_cached_counts\n",
    "    })\n",
    "\n",
    "    # Aggregate counts by move number\n",
    "    aggregated_df = df.groupby('move_number').sum()\n",
    "\n",
    "    # Plotting the stacked bar chart\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    aggregated_df.plot(kind='bar', stacked=True, color=['#003f5c', '#ffa600'], alpha=0.75, edgecolor='black')\n",
    "    plt.title('Cached vs. Not Cached Positions by Move Number')\n",
    "    plt.xlabel('Move Number')\n",
    "    plt.ylabel('Count of Positions')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_name = \"../../data/pipeline_test/processed_games.json\"\n",
    "    with open(file_name, 'r') as file:\n",
    "        games = json.load(file)\n",
    "\n",
    "    games = pd.DataFrame(games)\n",
    "    analyzed_games = get_analyzed_games(games)\n",
    "\n",
    "    plot_cached_positions_distribution(analyzed_games)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e39362-41f0-48d4-a40f-18e9ab283309",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aggregate counts by move number\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m aggregated_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmove_number\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plotting the stacked bar chart\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Aggregate counts by move number\n",
    "    aggregated_df = df.groupby('move_number').sum()\n",
    "\n",
    "    # Plotting the stacked bar chart\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    aggregated_df.plot(kind='bar', stacked=True, color=['#003f5c', '#ffa600'], alpha=0.75, edgecolor='black')\n",
    "    plt.title('Cached vs. Not Cached Positions by Move Number')\n",
    "    plt.xlabel('Move Number')\n",
    "    plt.ylabel('Count of Positions')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
