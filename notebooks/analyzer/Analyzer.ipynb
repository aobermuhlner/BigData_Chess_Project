{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe526a-53a4-4d15-ad8e-e443240d00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze games and save evaluation for each move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e780c8a-a357-4649-adcb-da0154173d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess #https://github.com/niklasf/python-chess\n",
    "from stockfish import Stockfish\n",
    "\n",
    "#We'll create an intentionally worse stockfish engine to estimate complexity of positions\n",
    "stockfish_good=Stockfish(\"C:/Users/aober/Documents/Data_Science_Studium/4Semester/BigData/stockfish/stockfish-windows-x86-64-avx2.exe\")\n",
    "stockfish_good.set_depth(15) \n",
    "stockfish_good.set_skill_level(15) \n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=999\n",
    "import datetime\n",
    "import tqdm\n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f049525-690f-423c-aae0-52c74989d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"apendra_games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a851f-956d-4eac-916e-b4a599b3c4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "games=pd.read_csv(f\"../../testData/{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f0ab3-b55c-489e-a3d6-2bf0838f0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_convert_to_int(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None  # or you can use np.nan or a placeholder like -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d4c6a-4170-4410-9e06-0e576f4dde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "games['moves']=games['moves'].apply(lambda x: eval(x))\n",
    "games['headers']=games['headers'].apply(lambda x: eval(x))#to dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4d3e3",
   "metadata": {},
   "source": [
    "# Running Stored Game\n",
    "All the functions down there, are used for the analysis.\n",
    "get_accuracy(): is a simpel approach of calcualting the acccuracy of an opening\n",
    "build_stored_game_analysis(): Is the evaluation of the game, the game is passed as a parameter an iterates over every move and uses the defined stockfish from the beginning of the document to evaluate the postion. In tis approach if the strongest version of stockfish is used, will be very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard point values for different pieces. Lowercase is white piece and uppercase is black\n",
    "piece_scores={\n",
    "    \"p\": 1,\n",
    "    \"P\": -1,\n",
    "    \"r\": 5,\n",
    "    \"R\": -5,\n",
    "    \"n\": 3,\n",
    "    \"N\": -3,\n",
    "    \"b\": 3,\n",
    "    \"B\": -3,\n",
    "    \"q\": 9,\n",
    "    \"Q\": -9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2797c-0825-4682-8cc2-08fbc47def35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(evaluation_change):\n",
    "    if (evaluation_change <= 25 and evaluation_change >= -25):\n",
    "        return 100\n",
    "    elif (evaluation_change > 25 and evaluation_change <= 50) or (evaluation_change < -25 and evaluation_change >= -50):\n",
    "        return 75\n",
    "    elif (evaluation_change > 50 and evaluation_change <= 75) or (evaluation_change < -50 and evaluation_change >= -75):\n",
    "        return 50\n",
    "    elif (evaluation_change > 75 and evaluation_change <= 100) or (evaluation_change < -75 and evaluation_change >= -100):\n",
    "        return 25\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e40ef-9c23-4f72-bd36-9b17c55ac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Used by chessnit.com\n",
    "def build_stored_game_analysis(game, move_number, prev_evaluation):\n",
    "    row={}\n",
    "    row['move_number']=move_number\n",
    "    row['taken']=[]\n",
    "    board=chess.Board()\n",
    "    for san in game['moves'][:move_number]:\n",
    "        parsed_san=board.parse_san(san)\n",
    "        taken=board.piece_at(parsed_san.to_square)\n",
    "        if taken:\n",
    "            row['taken'].append(taken.__str__())\n",
    "        move=board.push_san(san)\n",
    "    row['invalid']=bool(board.promoted) or bool(board.outcome())\n",
    "    stockfish_good.set_fen_position(board.fen())\n",
    "    evaluation=stockfish_good.get_evaluation()\n",
    "    row['evaluation']=evaluation['value']\n",
    "    row['evaluation_change']=evaluation['value']-prev_evaluation\n",
    "    row['accuracy'] = get_accuracy(row['evaluation_change'])\n",
    "    \n",
    "    \n",
    "    row['taken_score']=sum([piece_scores.get(p) for p in row['taken']])*100\n",
    "    row['fen']=board.fen()\n",
    "    row['url']=game['headers'].get(\"_tag_roster\", {}).get(\"Site\", \"\")+f\"#{move_number}\"\n",
    "    try:\n",
    "        row['last_move']=san\n",
    "    except:\n",
    "        print(game)\n",
    "        row['invalid']=True\n",
    "    return row, evaluation['value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870cd40-fdf0-402e-89b5-c4a191c94ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "def analyze_games(games, n, max_move_number):\n",
    "    all_game_analysis = []\n",
    "    \n",
    "    # Iterate over the first n games in the DataFrame\n",
    "    prev_evaluation  = 0\n",
    "    for i in tqdm.tqdm(range(min(n, len(games)))):\n",
    "        game = games.iloc[i]\n",
    "        game_analysis = []\n",
    "        \n",
    "        # Analyze each game up to the specified move number\n",
    "        for move_number in range(1, max_move_number + 1):\n",
    "            analysis_result, current_evaluation = build_stored_game_analysis(game, move_number,prev_evaluation)\n",
    "            game_analysis.append(analysis_result)\n",
    "            prev_evaluation = current_evaluation\n",
    "        # Store the analysis results for each game\n",
    "        all_game_analysis.append(pd.DataFrame(game_analysis).set_index(\"move_number\"))\n",
    "    \n",
    "    return all_game_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c3915-2a27-41bc-9d49-2dacc1b3f3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of games and the maximum move number you want to analyze\n",
    "n_games = 1000  # For example, analyze the first 10 games\n",
    "max_move_number = 10\n",
    "\n",
    "# Assuming 'games' is your DataFrame containing the games\n",
    "games_analysis = analyze_games(games, n_games, max_move_number)\n",
    "\n",
    "# Now, games_analysis is a list of DataFrames, each containing the analysis of one game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0ab04-3e23-4632-babc-bb15b01e24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be146f41-1943-4748-ac86-dd7cacad670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(games_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40710dad-6504-4f8e-97d7-d023e392a8de",
   "metadata": {},
   "source": [
    "# Save as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19fe54-5fea-46c3-a6c9-23c961036326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'games' DataFrame to a JSON file\n",
    "games[0:n_games].to_json(\"../../testData/games.json\", orient='records', lines=True)\n",
    "\n",
    "import json\n",
    "\n",
    "# Convert each DataFrame in the list to a dictionary\n",
    "games_analysis_dict = [df.to_dict(orient='records') for df in games_analysis]\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open(\"../../testData/games_analysis.json\", \"w\") as file:\n",
    "    json.dump(games_analysis_dict, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
